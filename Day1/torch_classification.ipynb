{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Classification \n",
    "\n",
    "Imvolves the following steps\n",
    "\n",
    "1. Import necessary libraries\n",
    "1. Generate synthetic data for Classifiation case and split the dataset\n",
    "1. Load data into loader into batches\n",
    "1. Create a simple model\n",
    "1. Initialize optimizer and loss function\n",
    "1. Strat  Training \n",
    "1. Draw the plots and Decision surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic classification dataset (moons)\n",
    "n_samples = 1000\n",
    "X_cls, y_cls = make_moons(n_samples=n_samples, noise=0.2, random_state=42)\n",
    "X_cls = torch.tensor(X_cls, dtype=torch.float32)\n",
    "y_cls = torch.tensor(y_cls, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, val, test sets (70%, 20%, 10%)\n",
    "X_train_cls, X_temp_cls, y_train_cls, y_temp_cls = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
    "X_val_cls, X_test_cls, y_val_cls, y_test_cls = train_test_split(X_temp_cls, y_temp_cls, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch processing\n",
    "train_dataset_cls = TensorDataset(X_train_cls, y_train_cls)\n",
    "val_dataset_cls = TensorDataset(X_val_cls, y_val_cls)\n",
    "test_dataset_cls = TensorDataset(X_test_cls, y_test_cls)\n",
    "\n",
    "train_loader_cls = DataLoader(train_dataset_cls, batch_size=32, shuffle=True)\n",
    "val_loader_cls = DataLoader(val_dataset_cls, batch_size=32, shuffle=False)\n",
    "test_loader_cls = DataLoader(test_dataset_cls, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model for classification\n",
    "class SimpleClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassificationModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 1)  # 2 input features, 1 output (binary classification)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classification model, loss function, and optimizer\n",
    "model_cls = SimpleClassificationModel()\n",
    "criterion_cls = nn.BCELoss()\n",
    "optimizer_cls = optim.Adam(model_cls.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_cls = 500\n",
    "losses_train_cls = []\n",
    "losses_val_cls = []\n",
    "accuracies_train_cls = []\n",
    "accuracies_val_cls = []\n",
    "\n",
    "for epoch in range(epochs_cls):\n",
    "    model_cls.train()\n",
    "    epoch_losses_train = []\n",
    "    epoch_correct_train = 0\n",
    "    epoch_total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, targets in train_loader_cls:\n",
    "        optimizer_cls.zero_grad()\n",
    "        outputs_train = model_cls(inputs)\n",
    "        loss_train = criterion_cls(outputs_train, targets.float().view(-1, 1))\n",
    "        loss_train.backward()\n",
    "        optimizer_cls.step()\n",
    "        epoch_losses_train.append(loss_train.item())\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predicted_train = (outputs_train > 0.5).float()\n",
    "        epoch_correct_train += (predicted_train == targets.float().view_as(predicted_train)).sum().item()\n",
    "        epoch_total_train += targets.size(0)\n",
    "\n",
    "    # Calculate mean loss and accuracy for the epoch\n",
    "    losses_train_cls.append(np.mean(epoch_losses_train))\n",
    "    accuracy_train = epoch_correct_train / epoch_total_train\n",
    "    accuracies_train_cls.append(accuracy_train)\n",
    "\n",
    "    # Evaluation phase (validation)\n",
    "    model_cls.eval()\n",
    "    epoch_losses_val = []\n",
    "    epoch_correct_val = 0\n",
    "    epoch_total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader_cls:\n",
    "            outputs_val = model_cls(inputs)\n",
    "            loss_val = criterion_cls(outputs_val, targets.float().view(-1, 1))\n",
    "            epoch_losses_val.append(loss_val.item())\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            predicted_val = (outputs_val > 0.5).float()\n",
    "            epoch_correct_val += (predicted_val == targets.float().view_as(predicted_val)).sum().item()\n",
    "            epoch_total_val += targets.size(0)\n",
    "\n",
    "    # Calculate mean loss and accuracy for validation set\n",
    "    losses_val_cls.append(np.mean(epoch_losses_val))\n",
    "    accuracy_val = epoch_correct_val / epoch_total_val\n",
    "    accuracies_val_cls.append(accuracy_val)\n",
    "\n",
    "    # Print progress every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch [{epoch}/{epochs_cls}], Train Loss: {losses_train_cls[-1]:.4f}, Val Loss: {losses_val_cls[-1]:.4f}, '\n",
    "              f'Train Acc: {accuracy_train:.4f}, Val Acc: {accuracy_val:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss, acc and decision surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses over epochs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses_train_cls, label='Training Loss')\n",
    "plt.plot(losses_val_cls, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Classification Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies_train_cls, label='Training Accuracy')\n",
    "plt.plot(accuracies_val_cls, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classification Training and Validation Accuracies')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate a meshgrid for decision contour plot\n",
    "x_min, x_max = X_cls[:, 0].min() - 0.5, X_cls[:, 0].max() + 0.5\n",
    "y_min, y_max = X_cls[:, 1].min() - 0.5, X_cls[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# Create input tensor from meshgrid for prediction\n",
    "mesh_tensor = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "model_cls.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model_cls(mesh_tensor)\n",
    "    outputs_pred = (outputs >= 0.5).float()  # Convert to class labels 0 or 1\n",
    "\n",
    "# Reshape outputs_pred to match xx and yy dimensions for plotting\n",
    "Z = outputs_pred.numpy().reshape(xx.shape)\n",
    "\n",
    "# Plot decision contours with different colors for each class and add colorbar\n",
    "plt.figure(figsize=(8, 6))\n",
    "contour = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X_cls[:, 0], X_cls[:, 1], c=y_cls, cmap=plt.cm.Paired, edgecolors='k')\n",
    "plt.title('Decision Boundary for Classification')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
